{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import utils\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from vgg_face_dag import vgg_face_dag\n",
    "from ami_model import AmIModel\n",
    "\n",
    "device = torch.device('cuda')\n",
    "# vgg_weight = './vgg_face_caffe.pth'\n",
    "vgg_weight = './vgg_face_dag.pth'\n",
    "# vgg_weight = './keras_vgg_face.pth'\n",
    "vgg_net = vgg_face_dag(vgg_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "register hook for relu1_1\n",
      "register hook for relu1_2\n",
      "register hook for pool1\n",
      "register hook for relu2_1\n",
      "register hook for relu2_2\n",
      "register hook for pool2\n",
      "register hook for relu3_1\n",
      "register hook for relu3_2\n",
      "register hook for relu3_3\n",
      "register hook for pool3\n",
      "register hook for relu4_1\n",
      "register hook for relu4_2\n",
      "register hook for relu4_3\n",
      "register hook for pool4\n",
      "register hook for relu5_1\n",
      "register hook for relu5_2\n",
      "register hook for relu5_3\n",
      "register hook for pool5\n",
      "register hook for relu6\n",
      "register hook for relu7\n"
     ]
    }
   ],
   "source": [
    "vgg_net.to(device)\n",
    "vgg_net.eval()\n",
    "\n",
    "SKIP_LAYERS = utils.SKIP_LAYERS\n",
    "ami_model = AmIModel(vgg_net)\n",
    "ami_model.eval()\n",
    "ami_model.register_my_hook(skip_layers=SKIP_LAYERS)\n",
    "\n",
    "# ami_model.show_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['leye', 'reye', 'nose', 'mouth']\n",
    "actions    = ['substitution', 'preservation']\n",
    "root_path  = '../../data/attribute_mutated/'\n",
    "base_img = '../../data/base_img.jpg'\n",
    "\n",
    "base_img_tensor = utils.get_data(base_img).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_witness(model, attri, base_img_tensor):\n",
    "    neuron_set_lists = OrderedDict()\n",
    "    model(base_img_tensor)\n",
    "    org_layouts = model.get_activation_values()\n",
    "    \n",
    "    for n,l in org_layouts.items():\n",
    "        neuron_set_lists[n] = set(range(l.shape[0]))\n",
    "    for img_name in os.listdir(root_path + attri + '_' + actions[0]):\n",
    "        attri_sub = root_path + attri + '_' + actions[0] + '/' + img_name\n",
    "        attri_pre = root_path + attri + '_' + actions[1] + '/' + img_name\n",
    "        \n",
    "        attri_sub_img_tensor = utils.get_data(attri_sub).to(device)\n",
    "        attri_pre_img_tensor = utils.get_data(attri_pre).to(device)\n",
    "        \n",
    "        model(attri_sub_img_tensor)\n",
    "        attri_sub_layouts = model.get_activation_values()\n",
    "        assert len(org_layouts) == len(attri_sub_layouts)\n",
    "        \n",
    "        for layer_idx in org_layouts.keys():\n",
    "            # print(f'strengthen computing {layer_idx}')\n",
    "            if attri_sub_layouts[layer_idx].shape != org_layouts[layer_idx].shape:\n",
    "                print(f'{layer_idx} has different shape, {attri_sub_layouts[layer_idx].shape} != {org_layouts[layer_idx].shape}')\n",
    "            if len(org_layouts[layer_idx].shape) == 1:\n",
    "                # fc layers\n",
    "                diff_layout = np.abs(attri_sub_layouts[layer_idx] - org_layouts[layer_idx])\n",
    "            else:\n",
    "                diff_layout = np.sum(np.abs(attri_sub_layouts[layer_idx] - org_layouts[layer_idx]), axis=(1,2))\n",
    "            sub_set = set([i for i,v in enumerate(diff_layout) if v > np.median(diff_layout)])\n",
    "            neuron_set_lists[layer_idx].intersection_update(sub_set) \n",
    "        \n",
    "        model(attri_pre_img_tensor)\n",
    "        attri_pre_layouts = model.get_activation_values()\n",
    "        assert len(org_layouts) == len(attri_pre_layouts)\n",
    "        \n",
    "        for layer_idx in org_layouts.keys():\n",
    "            # print(f'weaken computing {layer_idx}')\n",
    "            if len(org_layouts[layer_idx].shape) == 1:\n",
    "                # fc layers\n",
    "                diff_layout = np.abs(attri_pre_layouts[layer_idx] - org_layouts[layer_idx])\n",
    "            else:\n",
    "                diff_layout = np.sum(np.abs(attri_pre_layouts[layer_idx] - org_layouts[layer_idx]), axis=(1,2))\n",
    "            sub_set = set([i for i,v in enumerate(diff_layout) if v < np.median(diff_layout)])\n",
    "            neuron_set_lists[layer_idx].intersection_update(sub_set)\n",
    "    \n",
    "    res = []\n",
    "    for name, neuron_set in neuron_set_lists.items():\n",
    "        res.append('%s->%s' % (name, ','.join(map(str,sorted(neuron_set)))))\n",
    "        \n",
    "    print('Extracted witnesses:\\n\\t%s' % ('\\n\\t'.join(res)))\n",
    "    \n",
    "    with open(os.path.join('ami_data', f'{attri}_neurons.txt'), 'w') as out_file:\n",
    "        out_file.write('\\n'.join(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting witnesses for leye\n",
      "Extracted witnesses:\n",
      "\trelu1_1->42\n",
      "\trelu1_2->\n",
      "\tpool1->\n",
      "\trelu2_1->\n",
      "\trelu2_2->28,102\n",
      "\tpool2->28,102,106\n",
      "\trelu3_1->9,150,181,199\n",
      "\trelu3_2->20,126\n",
      "\trelu3_3->1,114,173\n",
      "\tpool3->1,181\n",
      "\trelu4_1->33,192,209,259,267,323,378,410,456\n",
      "\trelu4_2->181,206,292,392,481\n",
      "\trelu4_3->25,45,75,98,148,171,181,187,245,251,346,355,468,480,493\n",
      "\tpool4->75,91,171,187,329,468,484\n",
      "\trelu5_1->4,43,50,56,73,157,236,296,306,317,388,468\n",
      "\trelu5_2->147,223,328,377\n",
      "\trelu5_3->387\n",
      "\tpool5->227\n",
      "\trelu6->\n",
      "\trelu7->\n",
      "Extracting witnesses for reye\n",
      "Extracted witnesses:\n",
      "\trelu1_1->42\n",
      "\trelu1_2->\n",
      "\tpool1->\n",
      "\trelu2_1->\n",
      "\trelu2_2->28,69,102\n",
      "\tpool2->28,102,106\n",
      "\trelu3_1->6,9,150,181\n",
      "\trelu3_2->126,141,223\n",
      "\trelu3_3->98,236\n",
      "\tpool3->11,98,236\n",
      "\trelu4_1->26,33,135,192,267,323,410\n",
      "\trelu4_2->74,263,392\n",
      "\trelu4_3->0,25,91,108,252,273,274,355,446,468\n",
      "\tpool4->25,91,108,171,274,329,355,468,475\n",
      "\trelu5_1->87,157,177,249,324,384,416,468,483\n",
      "\trelu5_2->232\n",
      "\trelu5_3->\n",
      "\tpool5->\n",
      "\trelu6->\n",
      "\trelu7->\n",
      "Extracting witnesses for nose\n",
      "Extracted witnesses:\n",
      "\trelu1_1->42\n",
      "\trelu1_2->\n",
      "\tpool1->\n",
      "\trelu2_1->\n",
      "\trelu2_2->28\n",
      "\tpool2->28,102,106\n",
      "\trelu3_1->150,199\n",
      "\trelu3_2->\n",
      "\trelu3_3->174\n",
      "\tpool3->32,161,224\n",
      "\trelu4_1->33,204,246,271,278,312,323,410,419,446\n",
      "\trelu4_2->72,152,202,210,289,361,397,439\n",
      "\trelu4_3->15,33,46,98,108,170,187,194,236,256,326,331,346,373,388,417,480\n",
      "\tpool4->15,46,98,108,169,170,194,236,273,388,417,437,480\n",
      "\trelu5_1->69,88,317,442,483,484,509\n",
      "\trelu5_2->231,341\n",
      "\trelu5_3->273,353\n",
      "\tpool5->353\n",
      "\trelu6->\n",
      "\trelu7->\n",
      "Extracting witnesses for mouth\n",
      "Extracted witnesses:\n",
      "\trelu1_1->42\n",
      "\trelu1_2->\n",
      "\tpool1->\n",
      "\trelu2_1->\n",
      "\trelu2_2->28,69,102\n",
      "\tpool2->69,102\n",
      "\trelu3_1->116,117,150,181\n",
      "\trelu3_2->126,177,223\n",
      "\trelu3_3->11,32,40,48,51,59,98,109,117,122,132,135,144,151,173\n",
      "\tpool3->11,12,117,132,144,151,173\n",
      "\trelu4_1->26,42,94,116,164,179,232,246,253,271,308,312,323,412,440,446,466,470,496\n",
      "\trelu4_2->34,75,77,163,168,182,205,370,374,397,481,508\n",
      "\trelu4_3->0,33,58,104,105,167,235,238,339,388,442,446\n",
      "\tpool4->0,15,33,104,105,138,157,173,235,238,273\n",
      "\trelu5_1->24,81,133,143,198,272,402,467\n",
      "\trelu5_2->96,193\n",
      "\trelu5_3->233\n",
      "\tpool5->47,233\n",
      "\trelu6->\n",
      "\trelu7->\n"
     ]
    }
   ],
   "source": [
    "for attri in attributes:\n",
    "    print(f'Extracting witnesses for {attri}')\n",
    "    extract_witness(ami_model, attri, base_img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
